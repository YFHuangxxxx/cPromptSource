dataset: SMP2019_ECISA
templates:
  4f9d7b26-dd4a-4bc9-8394-dfbb283b5109: !Template
    answer_choices: "\u4E0D\u542B\u60C5\u611F ||| \u8912\u4E49\u9690\u5F0F\u60C5\u611F\
      \ ||| \u8D2C\u4E49\u9690\u5F0F\u60C5\u611F"
    id: 4f9d7b26-dd4a-4bc9-8394-dfbb283b5109
    jinja: "{{pre_text}}.{{text}}.{{last_pre}}\n\u8FD9\u6BB5\u6587\u672C\u4F5C\u8005\
      \u7684\u60C5\u611F\u6001\u5EA6\u662F\u7B80\u5355\u7684\u53D9\u8FF0\u4E0D\u542B\
      \u4EFB\u4F55\u60C5\u611F\u7684\u8FD8\u662F\u542B\u6709\u8912\u4E49\u9690\u5F0F\
      \u60C5\u611F\u7684\u8FD8\u662F\u542B\u6709\u8D2C\u4E49\u9690\u5F0F\u60C5\u611F\
      \u7684\uFF1F\n||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: attitude_with_choices_implicit
    reference: ''
  569c3fc5-8e55-4a1f-9963-647cc1560b99: !Template
    answer_choices: "\u4E0D\u542B\u60C5\u611F ||| \u8912\u4E49\u9690\u5F0F\u60C5\u611F\
      \ ||| \u8D2C\u4E49\u9690\u5F0F\u60C5\u611F"
    id: 569c3fc5-8e55-4a1f-9963-647cc1560b99
    jinja: "{{pre_text}}.{{text}}.{{last_pre}}\n\u4F5C\u8005\u5728\u4E0A\u9762\u7684\
      \u6587\u672C\u662F\u4EE5\u4E00\u79CD\u4EC0\u4E48\u6837\u7684\u60C5\u611F\u57FA\
      \u8C03\u6765\u5C55\u5F00\u53D9\u8FF0\u7684\uFF1F\n||| {{answer_choices [label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Writer_Expressed_Sentiment_implicit
    reference: ''
  6bf90e99-3f62-4dce-a5c9-6dd78116d6e9: !Template
    answer_choices: "\u4E0D\u542B\u60C5\u611F ||| \u8912\u4E49\u9690\u5F0F\u60C5\u611F\
      \ ||| \u8D2C\u4E49\u9690\u5F0F\u60C5\u611F"
    id: 6bf90e99-3f62-4dce-a5c9-6dd78116d6e9
    jinja: "{{pre_text}}.{{text}}.{{last_pre}}\n\u8FD9\u6BB5\u8BDD\u4E2D\u8BC4\u8BBA\
      \u8005\u6240\u60F3\u8868\u8FBE\u7684\u60C5\u611F\u662F\u4EC0\u4E48\uFF1F\n|||\
      \ {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: Reviewer_Expressed_Sentiment_implicit
    reference: ''
  b224c68b-30a0-44f9-b1cd-a63013109cbe: !Template
    answer_choices: "\u4E0D\u662F ||| \u4E0D\u662F ||| \u662F\u7684"
    id: b224c68b-30a0-44f9-b1cd-a63013109cbe
    jinja: "\u4E0B\u9762\u7684\u6587\u672C\u5185\u5BB9\u9690\u5F0F\u5730\u8868\u8FBE\
      \u4E86\u8D2C\u4E49\u7684\u60C5\u611F\u5417\uFF1F\n\u8BC4\u8BBA\uFF1A{{pre_text}}.{{text}}.{{last_pre}}\n\
      \u7B54\u6848\uFF1A |||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Is_negative_implicit
    reference: ''
  c21aa52f-9b20-4e83-88e1-39e514edbc9d: !Template
    answer_choices: "\u4E0D\u662F ||| \u662F\u7684 ||| \u4E0D\u662F"
    id: c21aa52f-9b20-4e83-88e1-39e514edbc9d
    jinja: "\u4E0B\u9762\u7684\u6587\u672C\u5185\u5BB9\u9690\u5F0F\u5730\u8868\u8FBE\
      \u4E86\u8912\u4E49\u7684\u60C5\u611F\u5417\uFF1F\n\u8BC4\u8BBA\uFF1A{{pre_text}}.{{text}}.{{last_pre}}\n\
      \u7B54\u6848\uFF1A |||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Is_positive_implicit
    reference: ''
